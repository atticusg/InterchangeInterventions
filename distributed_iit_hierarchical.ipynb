{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import utils\n",
    "from trainer import LIMTrainer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from LIM_deep_neural_classifier import LIMDeepNeuralClassifier\n",
    "import dataset_equality\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to change\n",
    "hidden_dim_per_slice = 4\n",
    "\n",
    "# Fixed variables\n",
    "device = \"cuda:9\"\n",
    "data_size = 640000\n",
    "embedding_dim = 4\n",
    "num_layers = 3\n",
    "max_iter = 10\n",
    "hidden_dim = hidden_dim_per_slice * 4\n",
    "input_dim = embedding_dim * 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate all the dataset, save it for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in {42, 77, 88}:\n",
    "    print(f\"generating dataset for seed={seed}\")\n",
    "    utils.fix_random_seeds(seed=seed)\n",
    "    pool = utils.generate_shape_pool(embedding_dim, data_size)\n",
    "    \n",
    "    factual_equality_dataset = utils.get_factual_task_from_pool(pool)\n",
    "    filehandler = open(f\"./datasets/iit_equality_dataset_factual_{seed}.obj\",\"wb\")\n",
    "    pickle.dump(factual_equality_dataset, filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    # oracle\n",
    "    iit_equality_dataset = \\\n",
    "        dataset_equality.get_IIT_equality_dataset_all(\n",
    "        embedding_dim, \n",
    "        data_size,\n",
    "        pool=pool\n",
    "    )\n",
    "    filehandler = open(f\"./datasets/iit_equality_dataset_oracle_{seed}.obj\",\"wb\")\n",
    "    pickle.dump(iit_equality_dataset, filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    # control (0)\n",
    "    key = {\n",
    "        \"left\":(0),\n",
    "        \"right\":()\n",
    "    }\n",
    "    train_datasetIIT = \\\n",
    "        dataset_equality.get_IIT_equality_dataset_control(\n",
    "        key, \n",
    "        embedding_dim,   \n",
    "        data_size,\n",
    "        pool=pool\n",
    "    )\n",
    "    filehandler = open(f\"./datasets/iit_equality_dataset_control_0_{seed}.obj\",\"wb\")\n",
    "    pickle.dump(train_datasetIIT, filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    # control (0, 1)\n",
    "    key = {\n",
    "        \"left\":(0,1),\n",
    "        \"right\":()\n",
    "    }\n",
    "    train_datasetIIT = \\\n",
    "        dataset_equality.get_IIT_equality_dataset_control(\n",
    "        key, \n",
    "        embedding_dim,   \n",
    "        data_size\n",
    "    )\n",
    "    filehandler = open(f\"./datasets/iit_equality_dataset_control_0_1_{seed}.obj\",\"wb\")\n",
    "    pickle.dump(train_datasetIIT, filehandler)\n",
    "    filehandler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train the factual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in {42, 77, 88}:\n",
    "    for hidden_dim in {32}: # {16, 32}\n",
    "        utils.fix_random_seeds(seed=seed)\n",
    "        print(f\"training factual model for seed={seed}\")\n",
    "        LIM = LIMDeepNeuralClassifier(\n",
    "            hidden_dim=hidden_dim, \n",
    "            hidden_activation=torch.nn.ReLU(), \n",
    "            num_layers=num_layers,\n",
    "            input_dim=input_dim,\n",
    "            n_classes=2,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        filehandler = open(f\"./datasets/iit_equality_dataset_factual_{seed}.obj\",'rb')\n",
    "        factual_equality_dataset = pickle.load(filehandler)\n",
    "        X_base_train, y_base_train = factual_equality_dataset\n",
    "\n",
    "        LIM_trainer = LIMTrainer(\n",
    "            LIM,\n",
    "            warm_start=True,\n",
    "            max_iter=max_iter,\n",
    "            batch_size=6400,\n",
    "            n_iter_no_change=10000,\n",
    "            shuffle_train=False,\n",
    "            eta=0.001,\n",
    "            save_checkpoint_per_epoch=True,\n",
    "            seed=seed\n",
    "        )\n",
    "\n",
    "        _ = LIM_trainer.fit(\n",
    "            X_base_train, \n",
    "            y_base_train, \n",
    "            iit_data=None,\n",
    "            intervention_ids_to_coords=None\n",
    "        )\n",
    "\n",
    "        datasetIIT = dataset_equality.get_IIT_equality_dataset_both(embedding_dim, 1000)\n",
    "        base_test, y_base_test, sources_test, y_IIT_test, intervention_ids_test = datasetIIT\n",
    "        base_preds = LIM_trainer.predict(base_test, device=\"cpu\")\n",
    "        print(classification_report(y_base_test, base_preds))\n",
    "\n",
    "        PATH = f\"./saved_models/basemodel-last-{num_layers}-{hidden_dim}-{seed}.bin\"\n",
    "        torch.save(LIM_trainer.model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train oracle model with d-IIT\n",
    "We should expect this to have a really high d-IIT accuracies! We evaluate these models in the next step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_c = 1\n",
    "total_model_c = 135\n",
    "for seed in {42, 77, 88}:\n",
    "    utils.fix_random_seeds(seed=seed)\n",
    "    filehandler = open(f\"./datasets/iit_equality_dataset_oracle_{seed}.obj\",'rb')\n",
    "    train_datasetIIT = pickle.load(filehandler)\n",
    "    filehandler.close()\n",
    "    X_base_train, y_base_train = train_datasetIIT[0:2]\n",
    "    iit_data = tuple(train_datasetIIT[2:])\n",
    "    for hidden_dim in {32}: # {16, 32}\n",
    "        for hidden_dim_per_concept in {0.5, 1, 4}:\n",
    "            for iit_layer in [0, 1, 2]:\n",
    "                scale_factor = hidden_dim/8\n",
    "                id_to_coords = {\n",
    "                    0: [{\"layer\": iit_layer, \"start\": 0, \"end\": int(scale_factor*hidden_dim_per_concept)}],\n",
    "                    1: [{\"layer\": iit_layer, \"start\":  int(scale_factor*hidden_dim_per_concept), \"end\": int(2*scale_factor*hidden_dim_per_concept)}],\n",
    "                    2: [{\"layer\": iit_layer, \"start\": 0, \"end\": int(scale_factor*hidden_dim_per_concept)}, \n",
    "                        {\"layer\": iit_layer, \"start\":  int(scale_factor*hidden_dim_per_concept), \"end\": int(2*scale_factor*hidden_dim_per_concept)}],\n",
    "                }\n",
    "                for i in [2, 4, 6, 8, 10]:\n",
    "                    print(f\"Training {model_c}/{total_model_c} model aligned with oracle hlm with params:\")\n",
    "                    print(f\"seed={seed}\")\n",
    "                    print(f\"hidden_dim_per_concept={hidden_dim_per_concept}\")\n",
    "                    print(f\"iit_layer={iit_layer}\")\n",
    "                    print(f\"epoch={i}\")\n",
    "                    LIM = LIMDeepNeuralClassifier(\n",
    "                        hidden_dim=hidden_dim, \n",
    "                        hidden_activation=torch.nn.ReLU(), \n",
    "                        num_layers=num_layers,\n",
    "                        input_dim=input_dim,\n",
    "                        n_classes=2,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    LIM_trainer = LIMTrainer(\n",
    "                        LIM,\n",
    "                        warm_start=True,\n",
    "                        max_iter=10,\n",
    "                        batch_size=6400, # we need to make sure in batch iit id is the same!\n",
    "                        n_iter_no_change=10000,\n",
    "                        shuffle_train=False,\n",
    "                        eta=0.001,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    PATH = f\"./saved_models/basemodel-{i}-{num_layers}-{hidden_dim}-{seed}.bin\"\n",
    "                    LIM_trainer.model.load_state_dict(torch.load(PATH))\n",
    "                    LIM_trainer.model.set_analysis_mode(True)\n",
    "\n",
    "                    _ = LIM_trainer.fit(\n",
    "                        X_base_train, \n",
    "                        y_base_train, \n",
    "                        iit_data=iit_data,\n",
    "                        intervention_ids_to_coords=id_to_coords)\n",
    "\n",
    "                    iit_layer_out = iit_layer + 1\n",
    "                    PATH = f\"./saved_models/iit-oraclemodel-epoch{i}-\"\\\n",
    "                           f\"{iit_layer_out}-{hidden_dim}-{hidden_dim_per_concept}-\"\\\n",
    "                           f\"{seed}.bin\"\n",
    "                    torch.save(LIM_trainer.model.state_dict(), PATH)\n",
    "\n",
    "                    model_c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate oracle model with d-IIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_results = []\n",
    "model_c = 1\n",
    "for seed in {42, 77, 88}: # {42, 66, 77}\n",
    "    utils.fix_random_seeds(seed=seed)\n",
    "    filehandler = open(f\"./datasets/iit_equality_dataset_oracle_{seed}.obj\",'rb')\n",
    "    train_datasetIIT = pickle.load(filehandler)\n",
    "    filehandler.close()\n",
    "    base_test_train, y_base_test_train, sources_test_train, y_IIT_test_train, intervention_ids_test_train = \\\n",
    "        utils.get_eval_from_train(\n",
    "            train_datasetIIT, 6400\n",
    "        )\n",
    "\n",
    "    base_test, y_base_test, sources_test, y_IIT_test, intervention_ids_test = \\\n",
    "        dataset_equality.get_IIT_equality_dataset_all(embedding_dim, 6400)\n",
    "    for hidden_dim in {16, 32}: # {16, 32}\n",
    "        for hidden_dim_per_concept in {0.5, 1, 4}: # {0.1, 1, 4}\n",
    "            for iit_layer in [0, 1, 2]: # {0, 1, 2}\n",
    "                scale_factor = hidden_dim/8\n",
    "                id_to_coords = {\n",
    "                    0: [{\"layer\": iit_layer, \"start\": 0, \"end\": int(scale_factor*hidden_dim_per_concept)}],\n",
    "                    1: [{\"layer\": iit_layer, \"start\":  int(scale_factor*hidden_dim_per_concept), \"end\": int(2*scale_factor*hidden_dim_per_concept)}],\n",
    "                    2: [{\"layer\": iit_layer, \"start\": 0, \"end\": int(scale_factor*hidden_dim_per_concept)}, \n",
    "                        {\"layer\": iit_layer, \"start\":  int(scale_factor*hidden_dim_per_concept), \"end\": int(2*scale_factor*hidden_dim_per_concept)}],\n",
    "                }\n",
    "                for i in [2, 4, 6, 8, 10]: # {2, 4, 6, 8, 10}\n",
    "                    # print(f\"Evaluating {model_c}/135 model aligned with oracle hlm.\")\n",
    "                    LIM = LIMDeepNeuralClassifier(\n",
    "                        hidden_dim=hidden_dim, \n",
    "                        hidden_activation=torch.nn.ReLU(), \n",
    "                        num_layers=num_layers,\n",
    "                        input_dim=input_dim,\n",
    "                        n_classes=2,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    LIM_trainer = LIMTrainer(\n",
    "                        LIM,\n",
    "                        warm_start=True,\n",
    "                        max_iter=10,\n",
    "                        batch_size=6400, # we need to make sure in batch iit id is the same!\n",
    "                        n_iter_no_change=10000,\n",
    "                        shuffle_train=False,\n",
    "                        eta=0.001,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    iit_layer_out = iit_layer + 1\n",
    "                    PATH = f\"./saved_models/iit-oraclemodel-epoch{i}-\"\\\n",
    "                           f\"{iit_layer_out}-{hidden_dim}-{hidden_dim_per_concept}-\"\\\n",
    "                           f\"{seed}.bin\"\n",
    "                    LIM_trainer.model.load_state_dict(torch.load(PATH))\n",
    "                    LIM_trainer.model.set_analysis_mode(True)\n",
    "\n",
    "                    # train data eval\n",
    "                    base_preds_train = LIM_trainer.predict(\n",
    "                        base_test_train, device=\"cpu\"\n",
    "                    )\n",
    "                    IIT_preds_train = LIM_trainer.iit_predict(\n",
    "                        base_test_train, sources_test_train, \n",
    "                        intervention_ids_test_train, \n",
    "                        id_to_coords, device=\"cpu\"\n",
    "                    )\n",
    "                    r1_train = classification_report(y_base_test_train, base_preds_train, output_dict=True)\n",
    "                    r2_train = classification_report(y_IIT_test_train, IIT_preds_train, output_dict=True)\n",
    "\n",
    "                    # test data eval\n",
    "                    base_preds = LIM_trainer.predict(\n",
    "                        base_test, device=\"cpu\"\n",
    "                    )\n",
    "                    IIT_preds = LIM_trainer.iit_predict(\n",
    "                        base_test, sources_test, \n",
    "                        intervention_ids_test, \n",
    "                        id_to_coords, device=\"cpu\"\n",
    "                    )\n",
    "                    r1 = classification_report(y_base_test, base_preds, output_dict=True)\n",
    "                    r2 = classification_report(y_IIT_test, IIT_preds, output_dict=True)\n",
    "\n",
    "                    oracle_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"Factual Train\", r1_train[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    oracle_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"d-IIT Train\", r2_train[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    oracle_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"Factual Test\", r1[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    oracle_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"d-IIT Test\", r2[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    model_c += 1\n",
    "oracle_df = pd.DataFrame(\n",
    "    oracle_results,\n",
    "    columns =['seed', 'hidden_dim', 'hidden_dim_per_concept', 'iit_layer', 'epoch', \n",
    "              'type', 'f1-score']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train (0, ) control model with d-IIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {\n",
    "    \"left\":0,\n",
    "    \"right\":( )\n",
    "}\n",
    "model_c = 1\n",
    "total_model_c = 135\n",
    "for seed in {42, 77, 88}:\n",
    "    filehandler = open(f\"./datasets/iit_equality_dataset_control_0_{seed}.obj\",'rb')\n",
    "    train_datasetIIT = pickle.load(filehandler)\n",
    "    filehandler.close()\n",
    "    X_base_train, y_base_train = train_datasetIIT[0:2]\n",
    "    iit_data = tuple(train_datasetIIT[2:])\n",
    "    for hidden_dim in {16, 32}: # {16, 32}\n",
    "        for hidden_dim_per_concept in {0.5, 1, 4}:\n",
    "            scale_factor = hidden_dim/8\n",
    "            for iit_layer in [0, 1, 2]:\n",
    "                if key[\"left\"] in [0,1] and key[\"right\"] in [0,1]:\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == (0,1) and key[\"right\"] == (0,1):\n",
    "                    key_size = 4\n",
    "                elif key[\"left\"] == (0,1) and key[\"right\"] == ():\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == () and key[\"right\"] == (0,1):\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == () or key[\"right\"] == ():\n",
    "                    key_size = 1\n",
    "                else:\n",
    "                    key_size = 3\n",
    "                control = 3\n",
    "                id_to_coords = {\n",
    "                    control:[{\n",
    "                        \"layer\": iit_layer, \n",
    "                        \"start\": 0, \n",
    "                        \"end\": int(scale_factor*key_size*hidden_dim_per_concept)\n",
    "                    }]\n",
    "                }\n",
    "                print(id_to_coords)\n",
    "                for i in [2,4,6,8,10]:\n",
    "                    print(f\"Training {model_c}/{total_model_c} model aligned with oracle hlm with params:\")\n",
    "                    print(f\"seed={seed}\")\n",
    "                    print(f\"hidden_dim_per_concept={hidden_dim_per_concept}\")\n",
    "                    print(f\"iit_layer={iit_layer}\")\n",
    "                    print(f\"epoch={i}\")\n",
    "                    LIM = LIMDeepNeuralClassifier(\n",
    "                        hidden_dim=hidden_dim, \n",
    "                        hidden_activation=torch.nn.ReLU(), \n",
    "                        num_layers=num_layers,\n",
    "                        input_dim=input_dim,\n",
    "                        n_classes=2,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    LIM_trainer = LIMTrainer(\n",
    "                        LIM,\n",
    "                        warm_start=True,\n",
    "                        max_iter=10,\n",
    "                        batch_size=6400, # we need to make sure in batch iit id is the same!\n",
    "                        n_iter_no_change=10000,\n",
    "                        shuffle_train=False,\n",
    "                        eta=0.001,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    PATH = f\"./saved_models/basemodel-{i}-{num_layers}-{hidden_dim}-{seed}.bin\"\n",
    "                    LIM_trainer.model.load_state_dict(torch.load(PATH))\n",
    "                    LIM_trainer.model.set_analysis_mode(True)\n",
    "\n",
    "                    _ = LIM_trainer.fit(\n",
    "                        X_base_train, \n",
    "                        y_base_train, \n",
    "                        iit_data=iit_data,\n",
    "                        intervention_ids_to_coords=id_to_coords)\n",
    "\n",
    "                    iit_layer_out = iit_layer + 1\n",
    "                    PATH = f\"./saved_models/iit-controlmodel-0-epoch{i}-\"\\\n",
    "                           f\"{iit_layer_out}-{hidden_dim}-{hidden_dim_per_concept}-\"\\\n",
    "                           f\"{seed}.bin\"\n",
    "                    torch.save(LIM_trainer.model.state_dict(), PATH)\n",
    "\n",
    "                    model_c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Eval (0, ) control model with d-IIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {\n",
    "    \"left\":0,\n",
    "    \"right\":( )\n",
    "}\n",
    "control_0_results = []\n",
    "model_c = 1\n",
    "for seed in {42, 77, 88}: # {42, 66, 77}\n",
    "    utils.fix_random_seeds(seed=seed)\n",
    "    filehandler = open(f\"./datasets/iit_equality_dataset_control_0_{seed}.obj\",'rb')\n",
    "    train_datasetIIT = pickle.load(filehandler)\n",
    "    filehandler.close()\n",
    "    base_test_train, y_base_test_train, sources_test_train, y_IIT_test_train, intervention_ids_test_train = \\\n",
    "        utils.get_eval_from_train(\n",
    "            train_datasetIIT, 6400*3, control=True\n",
    "        )\n",
    "\n",
    "    base_test, y_base_test, sources_test, y_IIT_test, intervention_ids_test = \\\n",
    "        dataset_equality.get_IIT_equality_dataset_control(\n",
    "        key, \n",
    "        embedding_dim,   \n",
    "        6400*3,\n",
    "    )\n",
    "    for hidden_dim in {16, 32}: # {16, 32}\n",
    "        for hidden_dim_per_concept in {0.5, 1, 4}:\n",
    "            scale_factor = hidden_dim/8\n",
    "            for iit_layer in [0, 1, 2]:\n",
    "                if key[\"left\"] in [0,1] and key[\"right\"] in [0,1]:\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == (0,1) and key[\"right\"] == (0,1):\n",
    "                    key_size = 4\n",
    "                elif key[\"left\"] == (0,1) and key[\"right\"] == ():\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == () and key[\"right\"] == (0,1):\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == () or key[\"right\"] == ():\n",
    "                    key_size = 1\n",
    "                else:\n",
    "                    key_size = 3\n",
    "                control = 3\n",
    "                id_to_coords = {\n",
    "                    control:[{\n",
    "                        \"layer\": iit_layer, \n",
    "                        \"start\": 0, \n",
    "                        \"end\": int(scale_factor*key_size*hidden_dim_per_concept)\n",
    "                    }]\n",
    "                }\n",
    "                for i in [2, 4, 6, 8, 10]: # {2, 4, 6, 8, 10}\n",
    "                    # print(f\"Evaluating {model_c}/135 model aligned with oracle hlm.\")\n",
    "                    LIM = LIMDeepNeuralClassifier(\n",
    "                        hidden_dim=hidden_dim, \n",
    "                        hidden_activation=torch.nn.ReLU(), \n",
    "                        num_layers=num_layers,\n",
    "                        input_dim=input_dim,\n",
    "                        n_classes=2,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    LIM_trainer = LIMTrainer(\n",
    "                        LIM,\n",
    "                        warm_start=True,\n",
    "                        max_iter=10,\n",
    "                        batch_size=6400, # we need to make sure in batch iit id is the same!\n",
    "                        n_iter_no_change=10000,\n",
    "                        shuffle_train=False,\n",
    "                        eta=0.001,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    iit_layer_out = iit_layer + 1\n",
    "                    PATH = f\"./saved_models/iit-controlmodel-0-epoch{i}-\"\\\n",
    "                           f\"{iit_layer_out}-{hidden_dim}-{hidden_dim_per_concept}-\"\\\n",
    "                           f\"{seed}.bin\"\n",
    "                    LIM_trainer.model.load_state_dict(torch.load(PATH))\n",
    "                    LIM_trainer.model.set_analysis_mode(True)\n",
    "\n",
    "                    # train data eval\n",
    "                    base_preds_train = LIM_trainer.predict(\n",
    "                        base_test_train, device=\"cpu\"\n",
    "                    )\n",
    "                    IIT_preds_train = LIM_trainer.iit_predict(\n",
    "                        base_test_train, sources_test_train, \n",
    "                        intervention_ids_test_train, \n",
    "                        id_to_coords, device=\"cpu\"\n",
    "                    )\n",
    "                    r1_train = classification_report(y_base_test_train, base_preds_train, output_dict=True)\n",
    "                    r2_train = classification_report(y_IIT_test_train, IIT_preds_train, output_dict=True)\n",
    "\n",
    "                    # test data eval\n",
    "                    base_preds = LIM_trainer.predict(\n",
    "                        base_test, device=\"cpu\"\n",
    "                    )\n",
    "                    IIT_preds = LIM_trainer.iit_predict(\n",
    "                        base_test, sources_test, \n",
    "                        intervention_ids_test, \n",
    "                        id_to_coords, device=\"cpu\"\n",
    "                    )\n",
    "                    r1 = classification_report(y_base_test, base_preds, output_dict=True)\n",
    "                    r2 = classification_report(y_IIT_test, IIT_preds, output_dict=True)\n",
    "\n",
    "                    control_0_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"Factual Train\", r1_train[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    control_0_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"d-IIT Train\", r2_train[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    control_0_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"Factual Test\", r1[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    control_0_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"d-IIT Test\", r2[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    model_c += 1\n",
    "control_0_df = pd.DataFrame(\n",
    "    control_0_results,\n",
    "    columns =['seed', 'hidden_dim', 'hidden_dim_per_concept', 'iit_layer', 'epoch', \n",
    "              'type', 'f1-score']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toplot = control_0_df[(control_0_df[\"hidden_dim_per_concept\"]==4)&\n",
    "   (control_0_df[\"iit_layer\"]==1)]\n",
    "sns.lineplot(\n",
    "    data=df_toplot,\n",
    "    x=\"epoch\", y=\"f1-score\", hue=\"type\", style=\"type\",\n",
    "    markers=True, dashes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train (0, 1) control model with d-IIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {\n",
    "    \"left\":(0,1),\n",
    "    \"right\":( )\n",
    "}\n",
    "model_c = 1\n",
    "total_model_c = 90\n",
    "for seed in {42, 77, 88}:\n",
    "    filehandler = open(f\"./datasets/iit_equality_dataset_control_0_1_{seed}.obj\",'rb')\n",
    "    train_datasetIIT = pickle.load(filehandler)\n",
    "    filehandler.close()\n",
    "    X_base_train, y_base_train = train_datasetIIT[0:2]\n",
    "    iit_data = tuple(train_datasetIIT[2:])\n",
    "    for hidden_dim in {32}: # {16, 32}\n",
    "        for hidden_dim_per_concept in {0.5, 1, 4}:\n",
    "            scale_factor = hidden_dim/16\n",
    "            for iit_layer in [0, 1, 2]:\n",
    "                if key[\"left\"] in [0,1] and key[\"right\"] in [0,1]:\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == (0,1) and key[\"right\"] == (0,1):\n",
    "                    key_size = 4\n",
    "                elif key[\"left\"] == (0,1) and key[\"right\"] == ():\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == () and key[\"right\"] == (0,1):\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == () or key[\"right\"] == ():\n",
    "                    key_size = 1\n",
    "                else:\n",
    "                    key_size = 3\n",
    "                control = 3\n",
    "                id_to_coords = {\n",
    "                    control:[{\n",
    "                        \"layer\": iit_layer, \n",
    "                        \"start\": 0, \n",
    "                        \"end\": int(scale_factor*key_size*hidden_dim_per_concept)\n",
    "                    }]\n",
    "                }\n",
    "                for i in [2,4,6,8,10]:\n",
    "                    print(f\"Training {model_c}/{total_model_c} model aligned with oracle hlm with params:\")\n",
    "                    print(f\"seed={seed}\")\n",
    "                    print(f\"hidden_dim_per_concept={hidden_dim_per_concept}\")\n",
    "                    print(f\"iit_layer={iit_layer}\")\n",
    "                    print(f\"epoch={i}\")\n",
    "                    LIM = LIMDeepNeuralClassifier(\n",
    "                        hidden_dim=hidden_dim, \n",
    "                        hidden_activation=torch.nn.ReLU(), \n",
    "                        num_layers=num_layers,\n",
    "                        input_dim=input_dim,\n",
    "                        n_classes=2,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    LIM_trainer = LIMTrainer(\n",
    "                        LIM,\n",
    "                        warm_start=True,\n",
    "                        max_iter=10,\n",
    "                        batch_size=6400, # we need to make sure in batch iit id is the same!\n",
    "                        n_iter_no_change=10000,\n",
    "                        shuffle_train=False,\n",
    "                        eta=0.001,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    PATH = f\"./saved_models/basemodel-{i}-{num_layers}-{hidden_dim}-{seed}.bin\"\n",
    "                    LIM_trainer.model.load_state_dict(torch.load(PATH))\n",
    "                    LIM_trainer.model.set_analysis_mode(True)\n",
    "\n",
    "                    _ = LIM_trainer.fit(\n",
    "                        X_base_train, \n",
    "                        y_base_train, \n",
    "                        iit_data=iit_data,\n",
    "                        intervention_ids_to_coords=id_to_coords)\n",
    "\n",
    "                    iit_layer_out = iit_layer + 1\n",
    "                    PATH = f\"./saved_models/iit-controlmodel-0-1-epoch{i}-\"\\\n",
    "                           f\"{iit_layer_out}-{hidden_dim}-{hidden_dim_per_concept}-\"\\\n",
    "                           f\"{seed}.bin\"\n",
    "                    torch.save(LIM_trainer.model.state_dict(), PATH)\n",
    "\n",
    "                    model_c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Eval (0, 1) control model with d-IIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {\n",
    "    \"left\":(0, 1),\n",
    "    \"right\":( )\n",
    "}\n",
    "control_0_1_results = []\n",
    "model_c = 1\n",
    "for seed in {42, 77, 88}: # {42, 66, 77}\n",
    "    utils.fix_random_seeds(seed=seed)\n",
    "    filehandler = open(f\"./datasets/iit_equality_dataset_control_0_1_{seed}.obj\",'rb')\n",
    "    train_datasetIIT = pickle.load(filehandler)\n",
    "    filehandler.close()\n",
    "    base_test_train, y_base_test_train, sources_test_train, y_IIT_test_train, intervention_ids_test_train = \\\n",
    "        utils.get_eval_from_train(\n",
    "            train_datasetIIT, 6400*3, control=True\n",
    "        )\n",
    "\n",
    "    base_test, y_base_test, sources_test, y_IIT_test, intervention_ids_test = \\\n",
    "        dataset_equality.get_IIT_equality_dataset_control(\n",
    "        key, \n",
    "        embedding_dim,   \n",
    "        6400*3,\n",
    "    )\n",
    "    for hidden_dim in {16, 32}: # {16, 32}\n",
    "        for hidden_dim_per_concept in {0.5, 1, 4}:\n",
    "            scale_factor = hidden_dim/16\n",
    "            for iit_layer in [0, 1, 2]:\n",
    "                if key[\"left\"] in [0,1] and key[\"right\"] in [0,1]:\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == (0,1) and key[\"right\"] == (0,1):\n",
    "                    key_size = 4\n",
    "                elif key[\"left\"] == (0,1) and key[\"right\"] == ():\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == () and key[\"right\"] == (0,1):\n",
    "                    key_size = 2\n",
    "                elif key[\"left\"] == () or key[\"right\"] == ():\n",
    "                    key_size = 1\n",
    "                else:\n",
    "                    key_size = 3\n",
    "                control = 3\n",
    "                id_to_coords = {\n",
    "                    control:[{\n",
    "                        \"layer\": iit_layer, \n",
    "                        \"start\": 0, \n",
    "                        \"end\": int(scale_factor*key_size*hidden_dim_per_concept)\n",
    "                    }]\n",
    "                }\n",
    "                for i in [2, 4, 6, 8, 10]: # {2, 4, 6, 8, 10}\n",
    "                    # print(f\"Evaluating {model_c}/135 model aligned with oracle hlm.\")\n",
    "                    LIM = LIMDeepNeuralClassifier(\n",
    "                        hidden_dim=hidden_dim, \n",
    "                        hidden_activation=torch.nn.ReLU(), \n",
    "                        num_layers=num_layers,\n",
    "                        input_dim=input_dim,\n",
    "                        n_classes=2,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    LIM_trainer = LIMTrainer(\n",
    "                        LIM,\n",
    "                        warm_start=True,\n",
    "                        max_iter=10,\n",
    "                        batch_size=6400, # we need to make sure in batch iit id is the same!\n",
    "                        n_iter_no_change=10000,\n",
    "                        shuffle_train=False,\n",
    "                        eta=0.001,\n",
    "                        device=device\n",
    "                    )\n",
    "\n",
    "                    iit_layer_out = iit_layer + 1\n",
    "                    PATH = f\"./saved_models/iit-controlmodel-0-1-epoch{i}-\"\\\n",
    "                           f\"{iit_layer_out}-{hidden_dim}-{hidden_dim_per_concept}-\"\\\n",
    "                           f\"{seed}.bin\"\n",
    "                    LIM_trainer.model.load_state_dict(torch.load(PATH))\n",
    "                    LIM_trainer.model.set_analysis_mode(True)\n",
    "\n",
    "                    # train data eval\n",
    "                    base_preds_train = LIM_trainer.predict(\n",
    "                        base_test_train, device=\"cpu\"\n",
    "                    )\n",
    "                    IIT_preds_train = LIM_trainer.iit_predict(\n",
    "                        base_test_train, sources_test_train, \n",
    "                        intervention_ids_test_train, \n",
    "                        id_to_coords, device=\"cpu\"\n",
    "                    )\n",
    "                    r1_train = classification_report(y_base_test_train, base_preds_train, output_dict=True)\n",
    "                    r2_train = classification_report(y_IIT_test_train, IIT_preds_train, output_dict=True)\n",
    "\n",
    "                    # test data eval\n",
    "                    base_preds = LIM_trainer.predict(\n",
    "                        base_test, device=\"cpu\"\n",
    "                    )\n",
    "                    IIT_preds = LIM_trainer.iit_predict(\n",
    "                        base_test, sources_test, \n",
    "                        intervention_ids_test, \n",
    "                        id_to_coords, device=\"cpu\"\n",
    "                    )\n",
    "                    r1 = classification_report(y_base_test, base_preds, output_dict=True)\n",
    "                    r2 = classification_report(y_IIT_test, IIT_preds, output_dict=True)\n",
    "\n",
    "                    control_0_1_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"Factual Train\", r1_train[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    control_0_1_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"d-IIT Train\", r2_train[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    control_0_1_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"Factual Test\", r1[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    control_0_1_results.append(\n",
    "                        [\n",
    "                            seed, hidden_dim, hidden_dim_per_concept, iit_layer_out, i, \n",
    "                            \"d-IIT Test\", r2[\"weighted avg\"][\"f1-score\"]]\n",
    "                    )\n",
    "                    model_c += 1\n",
    "control_0_1_df = pd.DataFrame(\n",
    "    control_0_1_results,\n",
    "    columns =['seed', 'hidden_dim', 'hidden_dim_per_concept', \n",
    "              'iit_layer', 'epoch', \n",
    "              'type', 'f1-score']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct results for the paper\n",
    "- oracle_df\n",
    "- control_0_df\n",
    "- control_0_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [16, 32]\n",
    "SCMs = [\"oracle\", \"control-0\", \"control-0-1\"]\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "for hidden_dim in hidden_dims:\n",
    "    for SCM in SCMs:\n",
    "\n",
    "        if SCM == \"oracle\":\n",
    "            df = oracle_df\n",
    "        elif SCM == \"control-0\":\n",
    "            df = control_0_df\n",
    "        elif SCM == \"control-0-1\":\n",
    "            df = control_0_1_df\n",
    "\n",
    "        plt.rcParams[\"font.family\"] = \"DejaVu Serif\"\n",
    "        font = {'family' : 'DejaVu Serif',\n",
    "                'size'   : 20}\n",
    "        plt.rc('font', **font)\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(14,10))\n",
    "\n",
    "        hidden_dim_per_concepts = [0.5, 1, 4]\n",
    "        iit_layers = [1, 2, 3]\n",
    "        if hidden_dim == 16:\n",
    "            ylabels = [f\"k=1\", f\"k=2\", f\"k=8\"]\n",
    "        else:\n",
    "            ylabels = [f\"k=2\", f\"k=4\", f\"k=16\"]\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                hidden_dim_per_concept = hidden_dim_per_concepts[i]\n",
    "                iit_layer = iit_layers[j]\n",
    "                df_toplot = df[(df[\"hidden_dim_per_concept\"]==hidden_dim_per_concept)&\n",
    "                   (df[\"iit_layer\"]==iit_layer)&\n",
    "                   (df[\"hidden_dim\"]==hidden_dim)&\n",
    "                   ((df[\"type\"]==\"Factual Train\")|\n",
    "                    (df[\"type\"]==\"d-IIT Train\")\n",
    "                    |(df[\"type\"]==\"Factual Test\")\n",
    "                    |(df[\"type\"]==\"d-IIT Test\"))\n",
    "                ]\n",
    "                sns.lineplot(\n",
    "                    ax=axes[i,j],\n",
    "                    data=df_toplot,\n",
    "                    x=\"epoch\", y=\"f1-score\", hue=\"type\", style=\"type\",\n",
    "                    dashes=False, markers=['o', 's', '^', 'D'], markersize=12, legend=False,\n",
    "                    alpha=0.8\n",
    "                )\n",
    "                axes[i,j].set_ylim(0.4, 1.1)\n",
    "                if i == 2:\n",
    "                    axes[i,j].set(xlabel=\"Epoch\" if j == 1 else None, xticks=[2, 4, 6, 8, 10], xticklabels=[2, 4, 6, 8, 10])\n",
    "                else:\n",
    "                    axes[i,j].set(xlabel=None, xticks=[2, 4, 6, 8, 10], xticklabels=[])\n",
    "                if j == 0:\n",
    "                    axes[i,j].set(ylabel=ylabels[i])\n",
    "                else:\n",
    "                    axes[i,j].set(ylabel=None, yticklabels=[])\n",
    "\n",
    "        axes[0,0].set_title(\"L1\")\n",
    "        axes[0,1].set_title(\"L2\")\n",
    "        axes[0,2].set_title(\"L3\")\n",
    "\n",
    "        plt.legend(loc='center right', labels=['Task Acc. (Train)', 'Int. Acc. (Train)', \n",
    "                                               'Task Acc. (Test)', 'Int. Acc. (Test)'], fontsize=14)\n",
    "\n",
    "        plt.savefig(f\"./fig/d-IIT-{hidden_dim}-{SCM}.png\",dpi=200, bbox_inches='tight')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_main_result_table(\n",
    "    oracle_df,\n",
    "    control_0_df,\n",
    "    control_0_1_df,\n",
    "    epoch = 10,\n",
    "    hidden_dim = 32,\n",
    "    reduce=max,\n",
    "    eval_setting=\"d-IIT Train\",\n",
    "    round_to=2\n",
    "):\n",
    "    rows = []\n",
    "    for hidden_dim_per_concept in [0.5, 1, 4]:\n",
    "        row_scores = []\n",
    "        for df in [oracle_df, control_0_1_df, control_0_df]:\n",
    "            selected_scores = []\n",
    "            for iit_layer in [1, 2, 3]:\n",
    "                selected_score = reduce(df[\n",
    "                    (df[\"hidden_dim_per_concept\"]==hidden_dim_per_concept)&\n",
    "                    (df[\"iit_layer\"]==iit_layer)&\n",
    "                    (df[\"hidden_dim\"]==hidden_dim)&\n",
    "                    (df[\"epoch\"]==epoch)&\n",
    "                    (df[\"type\"]==eval_setting)\n",
    "                ][\"f1-score\"].tolist())\n",
    "                selected_scores += [\"%.2f\" % round(selected_score, round_to)]\n",
    "            row_scores.extend(selected_scores)\n",
    "        rows += [row_scores]\n",
    "    df = pd.DataFrame(\n",
    "        rows, \n",
    "        columns=[\n",
    "            \"L1;SCM1\", \"L2;SCM1\", \"L3;SCM1\", \n",
    "            \"L1;SCM2\", \"L2;SCM2\", \"L3;SCM2\", \n",
    "            \"L1;SCM3\", \"L2;SCM3\", \"L3;SCM3\"\n",
    "        ]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_main_result_table(\n",
    "    oracle_df,\n",
    "    control_0_df,\n",
    "    control_0_1_df\n",
    ").to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
