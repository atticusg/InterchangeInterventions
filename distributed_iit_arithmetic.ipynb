{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "import torch, gc\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import utils\n",
    "from trainer import LIMTrainer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from LIM_deep_neural_classifier import LIMDeepNeuralClassifier\n",
    "import dataset_equality\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "utils.fix_random_seeds()\n",
    "\n",
    "def ab_c(a, b, c):\n",
    "    return (a+b)*c\n",
    "\n",
    "def get_IIT_arithmetic_dataset_factuals(\n",
    "    variable_range, seed,\n",
    "    data_size,\n",
    "    combiner_func\n",
    "):\n",
    "    random.seed(seed)\n",
    "    base = [[random.randint(\n",
    "        variable_range[0], variable_range[1]\n",
    "    ) for _ in range(3)] for _ in range(data_size)]\n",
    "    base_y = []\n",
    "    for b in base:\n",
    "        b_y = combiner_func(*b)\n",
    "        base_y += [b_y]\n",
    "        \n",
    "    return torch.tensor(base, dtype=torch.long), torch.tensor(base_y, dtype=torch.long)\n",
    "\n",
    "def get_IIT_arithmetic_dataset_factual_pairs(\n",
    "    variable_range, seed,\n",
    "    data_size,\n",
    "    combiner_func\n",
    "):\n",
    "    random.seed(seed)\n",
    "    base = [[random.randint(\n",
    "        variable_range[0], variable_range[1]\n",
    "    ) for _ in range(3)] for _ in range(data_size)]\n",
    "    base_y = []\n",
    "    for b in base:\n",
    "        b_y = combiner_func(*b)\n",
    "        base_y += [b_y]\n",
    "        \n",
    "    source = [[random.randint(\n",
    "        variable_range[0], variable_range[1]\n",
    "    ) for _ in range(3)] for _ in range(data_size)]\n",
    "    source_y = []\n",
    "    for s in source:\n",
    "        s_y = combiner_func(*s)\n",
    "        source_y += [s_y]\n",
    "        \n",
    "    return torch.tensor(base, dtype=torch.long), \\\n",
    "        torch.tensor(base_y, dtype=torch.long), \\\n",
    "        torch.tensor(source, dtype=torch.long), \\\n",
    "        torch.tensor(source_y, dtype=torch.long)\n",
    "\n",
    "def get_IIT_arithmetic_dataset_sum_first_V1(\n",
    "    variable_range, seed,\n",
    "    data_size,\n",
    "    combiner_func\n",
    "):\n",
    "    base, base_y, source, source_y = get_IIT_arithmetic_dataset_factual_pairs(\n",
    "        variable_range, seed,\n",
    "        data_size,\n",
    "        combiner_func\n",
    "    )\n",
    "    \n",
    "    source_sum = []\n",
    "    for s in source:\n",
    "        s_sum = s[0]+s[1]\n",
    "        source_sum += [s_sum]\n",
    "    \n",
    "    counterfactual_y = []\n",
    "    for i in range(len(base)):\n",
    "        c_y = source_sum[i]*base[i][-1]\n",
    "        counterfactual_y += [c_y]\n",
    "        \n",
    "    return torch.tensor(base, dtype=torch.long), \\\n",
    "        torch.tensor(base_y, dtype=torch.long), \\\n",
    "        torch.tensor(source, dtype=torch.long), \\\n",
    "        torch.tensor(counterfactual_y, dtype=torch.long), \\\n",
    "        torch.tensor([0 for _ in range(len(base))], dtype=torch.long)\n",
    "\n",
    "def get_IIT_arithmetic_dataset_sum_first_V2(\n",
    "    variable_range, seed,\n",
    "    data_size,\n",
    "    combiner_func\n",
    "):\n",
    "    base, base_y, source, source_y = get_IIT_arithmetic_dataset_factual_pairs(\n",
    "        variable_range, seed,\n",
    "        data_size,\n",
    "        combiner_func\n",
    "    )\n",
    "    \n",
    "    counterfactual_y = []\n",
    "    for i in range(len(base)):\n",
    "        c_y = (base[i][0]+base[i][1])*source[i][-1]\n",
    "        counterfactual_y += [c_y]\n",
    "        \n",
    "    return torch.tensor(base, dtype=torch.long), \\\n",
    "        torch.tensor(base_y, dtype=torch.long), \\\n",
    "        torch.tensor(source, dtype=torch.long), \\\n",
    "        torch.tensor(counterfactual_y, dtype=torch.long), \\\n",
    "        torch.tensor([1 for _ in range(len(base))], dtype=torch.long)\n",
    "\n",
    "def get_IIT_arithmetic_dataset_prod_first_V1(\n",
    "    variable_range, seed,\n",
    "    data_size,\n",
    "    combiner_func\n",
    "):\n",
    "    base, base_y, source, source_y = get_IIT_arithmetic_dataset_factual_pairs(\n",
    "        variable_range, seed,\n",
    "        data_size,\n",
    "        combiner_func\n",
    "    )\n",
    "    \n",
    "    counterfactual_y = []\n",
    "    for i in range(len(base)):\n",
    "        c_y = (base[i][1]*base[i][-1])+(source[i][0]*source[i][-1])\n",
    "        counterfactual_y += [c_y]\n",
    "        \n",
    "    return torch.tensor(base, dtype=torch.long), \\\n",
    "        torch.tensor(base_y, dtype=torch.long), \\\n",
    "        torch.tensor(source, dtype=torch.long), \\\n",
    "        torch.tensor(counterfactual_y, dtype=torch.long), \\\n",
    "        torch.tensor([0 for _ in range(len(base))], dtype=torch.long)\n",
    "\n",
    "def get_IIT_arithmetic_dataset_prod_first_V2(\n",
    "    variable_range, seed,\n",
    "    data_size,\n",
    "    combiner_func\n",
    "):\n",
    "    base, base_y, source, source_y = get_IIT_arithmetic_dataset_factual_pairs(\n",
    "        variable_range, seed,\n",
    "        data_size,\n",
    "        combiner_func\n",
    "    )\n",
    "    \n",
    "    counterfactual_y = []\n",
    "    for i in range(len(base)):\n",
    "        c_y = (base[i][0]*base[i][-1])+(source[i][1]*source[i][-1])\n",
    "        counterfactual_y += [c_y]\n",
    "        \n",
    "    return torch.tensor(base, dtype=torch.long), \\\n",
    "        torch.tensor(base_y, dtype=torch.long), \\\n",
    "        torch.tensor(source, dtype=torch.long), \\\n",
    "        torch.tensor(counterfactual_y, dtype=torch.long), \\\n",
    "        torch.tensor([1 for _ in range(len(base))], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IIT_arithmetic_dataset_control_V1(\n",
    "    variable_range, seed,\n",
    "    data_size,\n",
    "    combiner_func\n",
    "):\n",
    "    base, base_y, source, source_y = get_IIT_arithmetic_dataset_factual_pairs(\n",
    "        variable_range, seed,\n",
    "        data_size,\n",
    "        combiner_func\n",
    "    )\n",
    "    \n",
    "    counterfactual_y = []\n",
    "    for i in range(len(base)):\n",
    "        c_y = combiner_func(source[i][0], base[i][1], base[i][-1])\n",
    "        counterfactual_y += [c_y]\n",
    "        \n",
    "    return torch.tensor(base, dtype=torch.long), \\\n",
    "        torch.tensor(base_y, dtype=torch.long), \\\n",
    "        torch.tensor(source, dtype=torch.long), \\\n",
    "        torch.tensor(counterfactual_y, dtype=torch.long), \\\n",
    "        torch.tensor([2 for _ in range(len(base))], dtype=torch.long)\n",
    "\n",
    "def get_IIT_arithmetic_dataset_control_V2(\n",
    "    variable_range, seed,\n",
    "    data_size,\n",
    "    combiner_func\n",
    "):\n",
    "    base, base_y, source, source_y = get_IIT_arithmetic_dataset_factual_pairs(\n",
    "        variable_range, seed,\n",
    "        data_size,\n",
    "        combiner_func\n",
    "    )\n",
    "    \n",
    "    counterfactual_y = []\n",
    "    for i in range(len(base)):\n",
    "        c_y = combiner_func(base[i][0], source[i][1], base[i][-1])\n",
    "        counterfactual_y += [c_y]\n",
    "        \n",
    "    return torch.tensor(base, dtype=torch.long), \\\n",
    "        torch.tensor(base_y, dtype=torch.long), \\\n",
    "        torch.tensor(source, dtype=torch.long), \\\n",
    "        torch.tensor(counterfactual_y, dtype=torch.long), \\\n",
    "        torch.tensor([2 for _ in range(len(base))], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_range = [1, 9]\n",
    "X_base_train, y_base_train = get_IIT_arithmetic_dataset_factuals(\n",
    "    variable_range, 42, 640000, ab_c\n",
    ")\n",
    "min_y = (variable_range[0]+variable_range[0])*variable_range[0]\n",
    "max_y = (variable_range[1]+variable_range[1])*variable_range[1]\n",
    "classes = sorted(set([i for i in range(min_y, max_y+1)]))\n",
    "n_classes = (variable_range[1]+variable_range[1])*variable_range[1]\n",
    "class2index = dict(zip(classes, range(n_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 9\n",
    "device = \"cpu\"\n",
    "max_iter = 10\n",
    "\n",
    "LIM = LIMDeepNeuralClassifier(\n",
    "    hidden_dim=embedding_dim*3, \n",
    "    hidden_activation=torch.nn.ReLU(), \n",
    "    num_layers=2,\n",
    "    input_dim=embedding_dim*3,\n",
    "    n_classes=n_classes,\n",
    "    device=device,\n",
    "    vocab_size=(variable_range[1]-variable_range[0]+1),\n",
    "    embed_dim=embedding_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIM_trainer = LIMTrainer(\n",
    "    LIM,\n",
    "    warm_start=True,\n",
    "    max_iter=max_iter,\n",
    "    batch_size=6400,\n",
    "    n_iter_no_change=10000,\n",
    "    shuffle_train=False,\n",
    "    eta=0.001,\n",
    "    save_checkpoint_per_epoch=False,\n",
    "    input_as_ids=True,\n",
    "    device=device,\n",
    "    class2index=class2index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 10 of 10; error is 7.665561750531197"
     ]
    }
   ],
   "source": [
    "_ = LIM_trainer.fit(\n",
    "    X_base_train, \n",
    "    y_base_train, \n",
    "    iit_data=None,\n",
    "    intervention_ids_to_coords=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_test, y_base_test = get_IIT_arithmetic_dataset_factuals(\n",
    "    variable_range, 42, 1000, ab_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_preds = LIM_trainer.predict(base_test, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         9\n",
      "           7       1.00      1.00      1.00         5\n",
      "           8       1.00      1.00      1.00        10\n",
      "           9       1.00      1.00      1.00         9\n",
      "          10       1.00      1.00      1.00        19\n",
      "          11       1.00      1.00      1.00         6\n",
      "          12       1.00      1.00      1.00        23\n",
      "          13       1.00      1.00      1.00         4\n",
      "          14       1.00      1.00      1.00        18\n",
      "          15       1.00      1.00      1.00        12\n",
      "          16       1.00      1.00      1.00        11\n",
      "          17       1.00      1.00      1.00         5\n",
      "          18       1.00      1.00      1.00        28\n",
      "          20       1.00      1.00      1.00        26\n",
      "          21       1.00      1.00      1.00        17\n",
      "          22       1.00      1.00      1.00        14\n",
      "          24       1.00      1.00      1.00        35\n",
      "          25       1.00      1.00      1.00         4\n",
      "          26       1.00      1.00      1.00         8\n",
      "          27       1.00      1.00      1.00         9\n",
      "          28       1.00      1.00      1.00        27\n",
      "          30       1.00      1.00      1.00        31\n",
      "          32       1.00      1.00      1.00        19\n",
      "          33       1.00      1.00      1.00        10\n",
      "          34       1.00      1.00      1.00         1\n",
      "          35       1.00      1.00      1.00        13\n",
      "          36       1.00      1.00      1.00        31\n",
      "          39       1.00      1.00      1.00         8\n",
      "          40       1.00      1.00      1.00        34\n",
      "          42       1.00      1.00      1.00        28\n",
      "          44       1.00      1.00      1.00         9\n",
      "          45       1.00      1.00      1.00        19\n",
      "          48       1.00      1.00      1.00        33\n",
      "          49       1.00      1.00      1.00         6\n",
      "          50       1.00      1.00      1.00         9\n",
      "          51       1.00      1.00      1.00         8\n",
      "          52       1.00      1.00      1.00         9\n",
      "          54       1.00      1.00      1.00        24\n",
      "          55       1.00      1.00      1.00        12\n",
      "          56       1.00      1.00      1.00        20\n",
      "          60       1.00      1.00      1.00        37\n",
      "          63       1.00      1.00      1.00        15\n",
      "          64       1.00      1.00      1.00        15\n",
      "          65       1.00      1.00      1.00        11\n",
      "          66       1.00      1.00      1.00        10\n",
      "          68       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00        13\n",
      "          72       1.00      1.00      1.00        25\n",
      "          75       1.00      1.00      1.00         4\n",
      "          77       1.00      1.00      1.00         7\n",
      "          78       1.00      1.00      1.00         9\n",
      "          80       1.00      1.00      1.00        21\n",
      "          81       1.00      1.00      1.00        12\n",
      "          84       1.00      1.00      1.00        20\n",
      "          85       1.00      1.00      1.00         3\n",
      "          88       1.00      1.00      1.00        12\n",
      "          90       1.00      1.00      1.00        21\n",
      "          91       1.00      1.00      1.00        10\n",
      "          96       1.00      1.00      1.00        13\n",
      "          98       1.00      1.00      1.00         7\n",
      "          99       1.00      1.00      1.00        13\n",
      "         102       1.00      1.00      1.00         1\n",
      "         104       1.00      1.00      1.00         6\n",
      "         105       1.00      1.00      1.00        11\n",
      "         108       1.00      1.00      1.00         8\n",
      "         112       1.00      1.00      1.00         4\n",
      "         117       1.00      1.00      1.00         6\n",
      "         119       1.00      1.00      1.00         4\n",
      "         120       1.00      1.00      1.00         5\n",
      "         126       1.00      1.00      1.00        11\n",
      "         128       1.00      1.00      1.00         8\n",
      "         135       1.00      1.00      1.00         5\n",
      "         136       1.00      1.00      1.00         2\n",
      "         144       1.00      1.00      1.00        10\n",
      "         153       1.00      1.00      1.00         2\n",
      "         162       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_base_test, base_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"./saved_models/basemodel.bin\"\n",
    "torch.save(LIM_trainer.model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d-IIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "X_base_train, y_base_train, X_sources_train, y_IIT_train, intervention_ids_train = get_IIT_arithmetic_dataset_sum_first_V1(\n",
    "    variable_range, 42, 1280000, ab_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0\n",
    "id_to_coords = {\n",
    "    0: [{\"layer\": layer, \"start\": 0, \"end\": 2*embedding_dim}],\n",
    "}\n",
    "iit_data = ([X_sources_train], y_IIT_train, intervention_ids_train)\n",
    "PATH = f\"./saved_models/basemodel.bin\"\n",
    "LIM_trainer.model.load_state_dict(torch.load(PATH))\n",
    "LIM_trainer.model.set_analysis_mode(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 10 of 10; error is 327.2347227334976"
     ]
    }
   ],
   "source": [
    "_ = LIM_trainer.fit(\n",
    "    X_base_train, \n",
    "    y_base_train, \n",
    "    iit_data=iit_data,\n",
    "    intervention_ids_to_coords=id_to_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/afs/cs.stanford.edu/u/wuzhengx/.local/lib/python3.7/site-packages/ipykernel_launcher.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "X_base_test, y_base_test, X_sources_test, y_IIT_test, intervention_ids_test = get_IIT_arithmetic_dataset_sum_first_V1(\n",
    "    variable_range, 42, 1000, ab_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "IIT_preds = LIM_trainer.iit_predict(\n",
    "    X_base_test, [X_sources_test], \n",
    "    intervention_ids_test, \n",
    "    id_to_coords, device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.50      0.50      0.50         6\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.70      1.00      0.82         7\n",
      "           7       0.67      0.50      0.57         4\n",
      "           8       1.00      0.53      0.69        19\n",
      "           9       0.63      0.77      0.69        22\n",
      "          10       0.50      0.24      0.32        21\n",
      "          11       0.30      0.23      0.26        13\n",
      "          12       0.36      0.45      0.40        22\n",
      "          13       0.20      0.25      0.22         4\n",
      "          14       0.20      0.08      0.12        12\n",
      "          15       0.64      0.50      0.56        18\n",
      "          16       0.21      0.19      0.20        16\n",
      "          17       1.00      0.50      0.67         2\n",
      "          18       0.81      0.54      0.65        24\n",
      "          20       0.27      0.24      0.26        25\n",
      "          21       0.60      0.43      0.50         7\n",
      "          22       0.31      0.50      0.38         8\n",
      "          24       0.24      0.38      0.29        26\n",
      "          25       0.25      0.17      0.20         6\n",
      "          26       0.43      0.43      0.43         7\n",
      "          27       0.86      0.32      0.46        19\n",
      "          28       0.50      0.38      0.43        32\n",
      "          30       0.26      0.35      0.30        23\n",
      "          32       0.31      0.40      0.35        20\n",
      "          33       0.14      0.15      0.15        13\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.33      0.90      0.49        10\n",
      "          36       0.19      0.26      0.22        27\n",
      "          39       0.60      0.50      0.55         6\n",
      "          40       0.42      0.41      0.42        27\n",
      "          42       0.33      0.35      0.34        23\n",
      "          44       0.44      0.64      0.52        11\n",
      "          45       0.38      0.45      0.42        22\n",
      "          48       0.36      0.34      0.35        35\n",
      "          49       0.33      0.17      0.22         6\n",
      "          50       0.50      0.23      0.32        13\n",
      "          51       0.50      0.67      0.57         3\n",
      "          52       0.53      0.90      0.67        10\n",
      "          54       0.25      0.33      0.29        21\n",
      "          55       0.33      0.67      0.44         9\n",
      "          56       0.21      0.23      0.22        26\n",
      "          60       0.38      0.38      0.38        24\n",
      "          63       0.62      0.53      0.57        19\n",
      "          64       0.29      0.36      0.32        14\n",
      "          65       0.50      0.64      0.56        11\n",
      "          66       0.75      0.33      0.46         9\n",
      "          68       0.00      0.00      0.00         2\n",
      "          70       0.30      0.19      0.23        16\n",
      "          72       0.21      0.27      0.24        22\n",
      "          75       0.44      0.50      0.47         8\n",
      "          77       0.38      0.67      0.48         9\n",
      "          78       0.33      0.67      0.44         6\n",
      "          80       0.40      0.36      0.38        22\n",
      "          81       0.11      0.14      0.12         7\n",
      "          84       0.41      0.23      0.29        31\n",
      "          85       1.00      0.20      0.33         5\n",
      "          88       0.25      0.38      0.30         8\n",
      "          90       0.50      0.25      0.33        28\n",
      "          91       0.27      0.44      0.33         9\n",
      "          96       0.55      0.38      0.44        16\n",
      "          98       0.67      0.20      0.31        10\n",
      "          99       0.25      0.33      0.29         6\n",
      "         102       0.00      0.00      0.00         1\n",
      "         104       0.38      0.56      0.45         9\n",
      "         105       0.40      0.67      0.50         3\n",
      "         108       0.50      0.38      0.43         8\n",
      "         112       0.67      0.22      0.33        18\n",
      "         117       0.62      0.45      0.53        11\n",
      "         119       0.00      0.00      0.00         2\n",
      "         120       0.43      0.75      0.55         4\n",
      "         126       0.30      0.33      0.32         9\n",
      "         128       0.50      1.00      0.67         3\n",
      "         135       0.38      0.75      0.50         4\n",
      "         136       0.67      0.29      0.40         7\n",
      "         144       0.60      0.60      0.60         5\n",
      "         153       1.00      0.67      0.80         3\n",
      "         162       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.38      1000\n",
      "   macro avg       0.41      0.39      0.37      1000\n",
      "weighted avg       0.43      0.39      0.38      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_IIT_test, IIT_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
